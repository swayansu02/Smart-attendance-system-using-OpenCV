{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "af4f5a8b",
      "metadata": {
        "id": "af4f5a8b"
      },
      "source": [
        "# <h1><center>Smart Attendance System using OpenCV - Face recognition and attendance marking</center></h1>\n",
        "<center>By - Swayansu Mishra  </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af9c50c7",
      "metadata": {
        "id": "af9c50c7"
      },
      "source": [
        "As we discussed in the previous notebook the system consists of several key steps:\n",
        "\n",
        "1. Capturing images of individuals for training purposes\n",
        "2. Preprocessing the images and creating labels\n",
        "3. Splitting the dataset into training and testing sets\n",
        "4. Defining, compiling, and training a Convolutional Neural Network (CNN) model\n",
        "5. Marking attendance for recognized individuals in a CSV file\n",
        "6. Implementing a real-time face recognition system using the trained model\n",
        "7. Throughout this notebook, we provide detailed explanations, comments, and code sections to guide you through the development process.\n",
        "\n",
        "Out of all these we covered step 1 to 4 already. we will now focus on the remaining steps."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4c131cf",
      "metadata": {
        "id": "a4c131cf"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be4dd21b",
      "metadata": {
        "id": "be4dd21b"
      },
      "source": [
        "First, we need to import the necessary libraries for the project:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26dae4a1",
      "metadata": {
        "id": "26dae4a1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import time\n",
        "import pickle\n",
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c202bc2",
      "metadata": {
        "id": "7c202bc2"
      },
      "source": [
        "## Mark Attendance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad313199",
      "metadata": {
        "id": "ad313199"
      },
      "source": [
        "Next, we will create a function to mark attendance in a CSV file for the recognized person."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c557378b",
      "metadata": {
        "id": "c557378b"
      },
      "source": [
        "### Function to mark attendance in a CSV file"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b59a29a",
      "metadata": {
        "id": "5b59a29a"
      },
      "source": [
        "This function marks attendance for a recognized person by adding a new record with their name and the current time to the CSV file. If the attendance file for the current date does not exist, it creates a new file with appropriate headers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00d108d5",
      "metadata": {
        "id": "00d108d5"
      },
      "outputs": [],
      "source": [
        "def mark_attendance(name):\n",
        "    current_date = datetime.now().strftime('%Y-%m-%d')\n",
        "    filename = f\"attendance_{current_date}.csv\"\n",
        "    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    # Create a new CSV file if it does not exist\n",
        "    if not os.path.exists(filename):\n",
        "        with open(filename, 'w') as f:\n",
        "            f.write('Name,Time\\n')\n",
        "\n",
        "    # Read the CSV file and check if the person's attendance is already marked\n",
        "    df = pd.read_csv(filename)\n",
        "\n",
        "    # If the person's attendance is not marked, add a new record with the person's name and current time\n",
        "    if name not in df['Name'].values:\n",
        "        new_record = {'Name': name, 'Time': current_time}\n",
        "        df = df.append(new_record, ignore_index=True)\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(f\"Attendance marked for {name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56403784",
      "metadata": {
        "id": "56403784"
      },
      "source": [
        "## Real-time Attendance System"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17ae62b3",
      "metadata": {
        "id": "17ae62b3"
      },
      "source": [
        "Finally, we will create a function to start the real-time attendance system using the trained CNN model. This function will continuously capture video frames from the webcam, recognize the person's face, and mark attendance accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "890db669",
      "metadata": {
        "id": "890db669"
      },
      "source": [
        "We load the pre-trained Haar Cascade classifier for detecting frontal faces, which is available in the OpenCV library as `haarcascade_frontalface_default.xml`.\n",
        "\n",
        "Haar Cascade classifiers are based on the Haar-like features proposed by Paul Viola and Michael Jones in their paper, \"Rapid Object Detection using a Boosted Cascade of Simple Features.\" Haar-like features are simple rectangular patterns that can be used to detect edges, lines, and other patterns in images.\n",
        "\n",
        "A Haar Cascade classifier is a collection of multiple stages, each containing a set of weak classifiers. These weak classifiers are simple classifiers that can detect specific patterns with low accuracy. In each stage, the weak classifiers are combined into a stronger classifier using the AdaBoost algorithm. The classifiers in later stages are more complex and better at detecting the target object than those in earlier stages. During the detection process, an image is passed through these stages in a cascade, and if it passes all the stages, the object is detected.\n",
        "\n",
        "The `haarcascade_frontalface_default.xml` file is a pre-trained Haar Cascade classifier provided by OpenCV to detect frontal faces in images. This classifier has been trained on a large dataset of face and non-face images, and it can effectively detect faces in real-time when used with the OpenCV library."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "566b6732",
      "metadata": {
        "id": "566b6732"
      },
      "source": [
        "### Function to start the real-time attendance system"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f692ee01",
      "metadata": {
        "id": "f692ee01"
      },
      "source": [
        "In this function, we capture video frames from the webcam and process each frame to detect faces, recognize the person, and mark attendance. The detected faces are highlighted with a bounding box, and the recognized person's name is displayed above the box."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd6b3511",
      "metadata": {
        "id": "cd6b3511",
        "outputId": "3abc17c2-5266-40dc-93fb-6cb5448ea0f4"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'encoder' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 66>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Start the attendance system with the saved model\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m start_attendance(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mface_recognition_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mencoder\u001b[49m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'encoder' is not defined"
          ]
        }
      ],
      "source": [
        "def start_attendance(model_path, encoder):\n",
        "    # Load the saved model\n",
        "    model = load_model(model_path)\n",
        "    # Add cooldown period and cooldown_timestamps here\n",
        "    cooldown_period = 10\n",
        "    cooldown_timestamps = {}\n",
        "    \n",
        "    cap = cv2.VideoCapture('http://172.16.1.169:4747/video')\n",
        "#     cap = cv2.VideoCapture(0)\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "    # Loop to process the video frames\n",
        "    while True:\n",
        "        # Read frames from the webcam\n",
        "        ret, frame = cap.read()\n",
        "        # Convert the frames to grayscale\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        # Detect faces in the grayscale frames\n",
        "        faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.3, minNeighbors=5)\n",
        "\n",
        "        # Loop through the detected faces\n",
        "        for (x, y, w, h) in faces:\n",
        "            # Extract the region of interest (face) from the grayscale frame\n",
        "            roi_gray = gray_frame[y:y + h, x:x + w]\n",
        "            # Resize the face to match the input size of the CNN\n",
        "            resized_roi = cv2.resize(roi_gray, (96, 96))\n",
        "            # Convert the resized_roi to 3 channels\n",
        "            resized_roi_3_channels = np.repeat(resized_roi[..., np.newaxis], 3, axis=-1)\n",
        "            # Normalize the face and convert it to the required format for the CNN\n",
        "            roi_input = resized_roi_3_channels.reshape(1, 96, 96, 3).astype('float32') / 255.0\n",
        "\n",
        "            # Use the trained model to predict the person's name\n",
        "            confidence_threshold = 0.6\n",
        "            predictions = model.predict(roi_input)\n",
        "            label = np.argmax(predictions)\n",
        "            confidence = predictions[0][label]\n",
        "\n",
        "            if confidence > confidence_threshold:\n",
        "                name = encoder.inverse_transform([label])[0]\n",
        "                current_time = time.time()\n",
        "                \n",
        "                if name not in cooldown_timestamps or (current_time - cooldown_timestamps[name] >= cooldown_period):\n",
        "                    mark_attendance(name)\n",
        "                    cooldown_timestamps[name] = current_time\n",
        "            else:\n",
        "                name = \"Unknown\"\n",
        "            \n",
        "            # Draw a rectangle around the detected face and display the person's name\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
        "            cv2.putText(frame, name, (x + 6, y - 6), cv2.FONT_HERSHEY_DUPLEX, 0.5, (255, 255, 255), 1)\n",
        "\n",
        "        # Display the processed frames\n",
        "        cv2.imshow('Attendance System', frame)\n",
        "\n",
        "        # Exit the loop if the user presses 'q'\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    # Release the webcam and close the windows\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Start the attendance system with the saved model\n",
        "start_attendance('face_recognition_model.h5', encoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d00d6b69",
      "metadata": {
        "id": "d00d6b69"
      },
      "source": [
        "We will now load the saved encoder and start the attendance system with the saved model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21c0a3f6",
      "metadata": {
        "id": "21c0a3f6"
      },
      "outputs": [],
      "source": [
        "# Load the saved encoder\n",
        "with open('label_encoder.pkl', 'rb') as f:\n",
        "    loaded_encoder = pickle.load(f)\n",
        "    \n",
        "# Start the attendance system with the saved model\n",
        "start_attendance('face_recognition_model.h5', loaded_encoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f75e928",
      "metadata": {
        "id": "5f75e928"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52c498f0",
      "metadata": {
        "id": "52c498f0"
      },
      "source": [
        "In this project, we developed a Smart Attendance System that uses OpenCV and a Convolutional Neural Network to recognize faces and mark attendance in real-time. By capturing images of multiple people, training a model to recognize their faces, and implementing a real-time attendance system using a webcam, we have created an efficient and automated way to track attendance.\n",
        "\n",
        "We have also briefly discussed the Haar Cascade classifier and the `haarcascade_frontalface_default.xml` file, which is a pre-trained classifier for detecting frontal faces in images. This classifier is an essential component of our system, as it enables us to detect faces in the video frames captured by the webcam."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}